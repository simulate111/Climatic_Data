{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "turku_finland_meteorological_institute_FMI(2015-2024)10minutes.ipynb",
      "authorship_tag": "ABX9TyNNxof3m+eKqUz98p5C1jT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Climatic_Data/blob/main/turku_finland_meteorological_institute_FMI(2015_2024)10minutes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxlyr4KCnLd0",
        "outputId": "b26a844a-3337-4a5c-db69-c1f644c23b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Extraction for Turku (2015-2024)...\n",
            "\n",
            "--- Processing Year 2015 ---\n",
            "   > Fetching Weather... ...... Done (104956 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2016 ---\n",
            "   > Fetching Weather... ...... Done (105298 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2017 ---\n",
            "   > Fetching Weather... ...... Done (104994 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2018 ---\n",
            "   > Fetching Weather... ...... Done (105113 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2019 ---\n",
            "   > Fetching Weather... ...... Done (104741 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2020 ---\n",
            "   > Fetching Weather... ...... Done (104784 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2021 ---\n",
            "   > Fetching Weather... ...... Done (104979 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2022 ---\n",
            "   > Fetching Weather... ...... Done (104591 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2023 ---\n",
            "   > Fetching Weather... ...... Done (101496 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "--- Processing Year 2024 ---\n",
            "   > Fetching Weather... ...... Done (104274 records)\n",
            "   > Fetching Radiation... ...... Done (0 records)\n",
            "\n",
            "Merging all years...\n",
            "Calculating 10-Year 10-Minute Averages...\n",
            "Success! Generated 52704 rows.\n",
            "Type Display_Date Display_Time  Temperature_C  Wind_Speed_ms\n",
            "0           01-01        00:00         -0.715       2.955556\n",
            "1           01-01        00:10         -0.600       2.522222\n",
            "2           01-01        00:20         -0.640       2.877778\n",
            "3           01-01        00:30         -0.770       2.822222\n",
            "4           01-01        00:40         -0.730       2.755556\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Turku Artukainen (Temperature/Wind)\n",
        "STATION_ID_WEATHER = \"100949\"\n",
        "\n",
        "# Turku Area Solar (Kaarina Ylt√∂inen ~10km away)\n",
        "# Artukainen often lacks solar sensors; Kaarina is the reliable source.\n",
        "STATION_ID_SOLAR = \"100932\"\n",
        "\n",
        "YEARS = range(2015, 2025) # 2015-2024\n",
        "OUTPUT_FILE = \"Turku_10Yr_10Min_Averages_2015-2024.csv\"\n",
        "\n",
        "# TASKS\n",
        "tasks = [\n",
        "    {\n",
        "        \"name\": \"Weather\",\n",
        "        \"station\": STATION_ID_WEATHER,\n",
        "        \"query\": \"fmi::observations::weather::simple\",\n",
        "        \"params\": \"t2m,ws_10min\",\n",
        "        \"map\": {\"t2m\": \"Temperature_C\", \"ws_10min\": \"Wind_Speed_ms\"}\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Radiation\",\n",
        "        \"station\": STATION_ID_SOLAR,\n",
        "        \"query\": \"fmi::observations::radiation::simple\",\n",
        "        \"params\": \"r_10min\", # Global radiation 10min average\n",
        "        \"map\": {\"r_10min\": \"Global_Radiation_Wm2\"}\n",
        "    }\n",
        "]\n",
        "\n",
        "def get_chunks(start_date, end_date):\n",
        "    # FMI WFS limits responses, so we break requests into 7-day chunks\n",
        "    s = datetime.strptime(start_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    e = datetime.strptime(end_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "    chunks = []\n",
        "    curr = s\n",
        "    while curr < e:\n",
        "        nxt = min(curr + timedelta(days=7), e)\n",
        "        chunks.append((curr.strftime('%Y-%m-%dT%H:%M:%SZ'), nxt.strftime('%Y-%m-%dT%H:%M:%SZ')))\n",
        "        curr = nxt\n",
        "    return chunks\n",
        "\n",
        "def fetch_fmi_data(task, start_ch, end_ch):\n",
        "    \"\"\"Fetches a single chunk of data from FMI\"\"\"\n",
        "    params = {\n",
        "        \"service\": \"WFS\", \"version\": \"2.0.0\", \"request\": \"getFeature\",\n",
        "        \"storedquery_id\": task['query'],\n",
        "        \"fmisid\": task['station'],\n",
        "        \"parameters\": task['params'],\n",
        "        \"starttime\": start_ch, \"endtime\": end_ch\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(\"http://opendata.fmi.fi/wfs\", params=params, timeout=10)\n",
        "        if r.status_code == 200:\n",
        "            root = ET.fromstring(r.content)\n",
        "            ns = {'wfs': 'http://www.opengis.net/wfs/2.0', 'BsWfs': 'http://xml.fmi.fi/schema/wfs/2.0'}\n",
        "\n",
        "            rows = []\n",
        "            for member in root.findall('.//wfs:member', ns):\n",
        "                elm = member.find('.//BsWfs:BsWfsElement', ns)\n",
        "                if elm is not None:\n",
        "                    t = elm.find('BsWfs:Time', ns).text\n",
        "                    p = elm.find('BsWfs:ParameterName', ns).text\n",
        "                    v_node = elm.find('BsWfs:ParameterValue', ns)\n",
        "\n",
        "                    try:\n",
        "                        val_text = v_node.text\n",
        "                        if val_text and val_text != 'NaN':\n",
        "                            v = float(val_text)\n",
        "                            # FMI solar is sometimes negative at night (sensor noise), clamp to 0\n",
        "                            if \"Radiation\" in task['name'] and v < 0:\n",
        "                                v = 0\n",
        "                            rows.append({'Time': t, 'Type': task['map'][p], 'Value': v})\n",
        "                    except: continue\n",
        "            return rows\n",
        "    except Exception as e:\n",
        "        print(f\"    ! Error: {e}\")\n",
        "    return []\n",
        "\n",
        "# --- MAIN LOOP ---\n",
        "all_data_frames = []\n",
        "\n",
        "print(f\"Starting Extraction for Turku ({YEARS[0]}-{YEARS[-1]})...\")\n",
        "\n",
        "# We loop by Year first to keep memory manageable\n",
        "for year in YEARS:\n",
        "    print(f\"\\n--- Processing Year {year} ---\")\n",
        "    start_str = f\"{year}-01-01\"\n",
        "    end_str = f\"{year+1}-01-01\"\n",
        "    chunks = get_chunks(start_str, end_str)\n",
        "\n",
        "    year_rows = []\n",
        "\n",
        "    # Process both tasks (Weather + Radiation)\n",
        "    for task in tasks:\n",
        "        print(f\"   > Fetching {task['name']}...\", end=\" \", flush=True)\n",
        "        count = 0\n",
        "        for i, (s_ch, e_ch) in enumerate(chunks):\n",
        "            chunk_data = fetch_fmi_data(task, s_ch, e_ch)\n",
        "            year_rows.extend(chunk_data)\n",
        "            count += len(chunk_data)\n",
        "            # Simple progress indicator\n",
        "            if i % 10 == 0: print(\".\", end=\"\", flush=True)\n",
        "            time.sleep(0.05)\n",
        "        print(f\" Done ({count} records)\")\n",
        "\n",
        "    if year_rows:\n",
        "        df = pd.DataFrame(year_rows)\n",
        "        df['Time'] = pd.to_datetime(df['Time'])\n",
        "\n",
        "        # Pivot to get columns: [Time, Temperature_C, Wind_Speed_ms, Global_Radiation_Wm2]\n",
        "        # We use 'last' to handle duplicates if any overlap occurred\n",
        "        df_pivot = df.pivot_table(index='Time', columns='Type', values='Value', aggfunc='last')\n",
        "\n",
        "        # Resample to strict 10-min grid to align Weather and Solar\n",
        "        df_pivot = df_pivot.resample('10min').mean()\n",
        "\n",
        "        # Interpolate small gaps (up to 1 hour)\n",
        "        df_pivot = df_pivot.interpolate(method='time', limit=6)\n",
        "\n",
        "        all_data_frames.append(df_pivot)\n",
        "\n",
        "# --- MERGE & AVERAGE ---\n",
        "if all_data_frames:\n",
        "    print(\"\\nMerging all years...\")\n",
        "    master_df = pd.concat(all_data_frames)\n",
        "\n",
        "    # Filter cleanup\n",
        "    if 'Global_Radiation_Wm2' in master_df.columns:\n",
        "        master_df['Global_Radiation_Wm2'] = master_df['Global_Radiation_Wm2'].fillna(0)\n",
        "\n",
        "    print(\"Calculating 10-Year 10-Minute Averages...\")\n",
        "\n",
        "    # 1. Group by Month, Day, Hour, MINUTE\n",
        "    # Note: FMI times are UTC.\n",
        "    grouped = master_df.groupby([\n",
        "        master_df.index.month,\n",
        "        master_df.index.day,\n",
        "        master_df.index.hour,\n",
        "        master_df.index.minute\n",
        "    ]).mean()\n",
        "\n",
        "    grouped.index.names = ['Month', 'Day', 'Hour', 'Minute']\n",
        "    df_avg = grouped.reset_index()\n",
        "\n",
        "    # 2. Create Dummy Timestamp for Display (using 2024 for Leap Year safety)\n",
        "    df_avg['Dummy_Timestamp'] = pd.to_datetime(\n",
        "        '2024-' + df_avg['Month'].astype(str) + '-' + df_avg['Day'].astype(str) + ' ' +\n",
        "        df_avg['Hour'].astype(str) + ':' + df_avg['Minute'].astype(str) + ':00',\n",
        "        errors='coerce'\n",
        "    )\n",
        "    df_avg = df_avg.dropna(subset=['Dummy_Timestamp']).sort_values('Dummy_Timestamp')\n",
        "\n",
        "    # 3. Format Output\n",
        "    df_avg['Display_Date'] = df_avg['Dummy_Timestamp'].dt.strftime('%m-%d')\n",
        "    df_avg['Display_Time'] = df_avg['Dummy_Timestamp'].dt.strftime('%H:%M')\n",
        "\n",
        "    # Select columns if they exist\n",
        "    cols = ['Display_Date', 'Display_Time', 'Temperature_C', 'Wind_Speed_ms', 'Global_Radiation_Wm2']\n",
        "    final_cols = [c for c in cols if c in df_avg.columns]\n",
        "\n",
        "    final_output = df_avg[final_cols]\n",
        "\n",
        "    print(f\"Success! Generated {len(final_output)} rows.\")\n",
        "    print(final_output.head())\n",
        "    final_output.to_csv(OUTPUT_FILE, index=False)\n",
        "else:\n",
        "    print(\"No data retrieved.\")"
      ]
    }
  ]
}