{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjJmtHpGsbPUOoFotp9whu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Climatic_Data/blob/main/turku_era5_cds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "\n",
        "# The precise City Center coordinates we chose\n",
        "lat, lon = 60.5, 22.3\n",
        "\n",
        "# 1. Initialize the map centered on Turku\n",
        "# We use 'cartodbpositron' for a clean, professional look that highlights markers\n",
        "m = folium.Map(location=[lat, lon], zoom_start=12, control_scale=True)\n",
        "\n",
        "# 2. Add a marker for the exact Grid Center\n",
        "folium.Marker(\n",
        "    [lat, lon],\n",
        "    popup=\"<b>ERA5-Land Grid Center</b><br>Lat: 60.5, Lon: 22.3\",\n",
        "    tooltip=\"Turku City Center Point\",\n",
        "    icon=folium.Icon(color='darkred', icon='info-sign')\n",
        ").add_to(m)\n",
        "\n",
        "# 3. Add a rectangle to show the ERA5-Land Grid Cell (approx 0.1 x 0.1 degrees)\n",
        "# This represents the actual area the weather data is calculated for.\n",
        "folium.Rectangle(\n",
        "    bounds=[[60.45, 22.25], [60.55, 22.35]],\n",
        "    color=\"blue\",\n",
        "    fill=True,\n",
        "    fill_opacity=0.1,\n",
        "    popup=\"Approximate 9km Grid Cell Area\"\n",
        ").add_to(m)\n",
        "\n",
        "# 4. Add a reference marker for the Market Square (Kauppatori)\n",
        "# to see how close it is to our data point.\n",
        "folium.CircleMarker(\n",
        "    location=[60.4515, 22.2672],\n",
        "    radius=5,\n",
        "    color=\"green\",\n",
        "    fill=True,\n",
        "    popup=\"Market Square (City Center)\"\n",
        ").add_to(m)\n",
        "\n",
        "# Display the map in Colab\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "d37iTantaZ1p",
        "outputId": "64efb748-516e-45e4-aa99-6e16f310593b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x78d7e2464b30>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_4565ae6e5223343852e352e7140137cd {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "\n",
              "            &lt;style&gt;html, body {\n",
              "                width: 100%;\n",
              "                height: 100%;\n",
              "                margin: 0;\n",
              "                padding: 0;\n",
              "            }\n",
              "            &lt;/style&gt;\n",
              "\n",
              "            &lt;style&gt;#map {\n",
              "                position:absolute;\n",
              "                top:0;\n",
              "                bottom:0;\n",
              "                right:0;\n",
              "                left:0;\n",
              "                }\n",
              "            &lt;/style&gt;\n",
              "\n",
              "            &lt;script&gt;\n",
              "                L_NO_TOUCH = false;\n",
              "                L_DISABLE_3D = false;\n",
              "            &lt;/script&gt;\n",
              "\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_4565ae6e5223343852e352e7140137cd&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_4565ae6e5223343852e352e7140137cd = L.map(\n",
              "                &quot;map_4565ae6e5223343852e352e7140137cd&quot;,\n",
              "                {\n",
              "                    center: [60.5, 22.3],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    ...{\n",
              "  &quot;zoom&quot;: 12,\n",
              "  &quot;zoomControl&quot;: true,\n",
              "  &quot;preferCanvas&quot;: false,\n",
              "}\n",
              "\n",
              "                }\n",
              "            );\n",
              "            L.control.scale().addTo(map_4565ae6e5223343852e352e7140137cd);\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_790f47a03299d978e988c9512b1be06e = L.tileLayer(\n",
              "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {\n",
              "  &quot;minZoom&quot;: 0,\n",
              "  &quot;maxZoom&quot;: 19,\n",
              "  &quot;maxNativeZoom&quot;: 19,\n",
              "  &quot;noWrap&quot;: false,\n",
              "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
              "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
              "  &quot;detectRetina&quot;: false,\n",
              "  &quot;tms&quot;: false,\n",
              "  &quot;opacity&quot;: 1,\n",
              "}\n",
              "\n",
              "            );\n",
              "        \n",
              "    \n",
              "            tile_layer_790f47a03299d978e988c9512b1be06e.addTo(map_4565ae6e5223343852e352e7140137cd);\n",
              "        \n",
              "    \n",
              "            var marker_975b24a1fbb6d562f58f172286a06f5d = L.marker(\n",
              "                [60.5, 22.3],\n",
              "                {\n",
              "}\n",
              "            ).addTo(map_4565ae6e5223343852e352e7140137cd);\n",
              "        \n",
              "    \n",
              "            var icon_465ccf10f651758d871749fe023615de = L.AwesomeMarkers.icon(\n",
              "                {\n",
              "  &quot;markerColor&quot;: &quot;darkred&quot;,\n",
              "  &quot;iconColor&quot;: &quot;white&quot;,\n",
              "  &quot;icon&quot;: &quot;info-sign&quot;,\n",
              "  &quot;prefix&quot;: &quot;glyphicon&quot;,\n",
              "  &quot;extraClasses&quot;: &quot;fa-rotate-0&quot;,\n",
              "}\n",
              "            );\n",
              "        \n",
              "    \n",
              "        var popup_1914bce5423d2b04c09b9c4c535537f5 = L.popup({\n",
              "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
              "});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_98d2313affb312b309ea2d27b025ab3f = $(`&lt;div id=&quot;html_98d2313affb312b309ea2d27b025ab3f&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;&lt;b&gt;ERA5-Land Grid Center&lt;/b&gt;&lt;br&gt;Lat: 60.5, Lon: 22.3&lt;/div&gt;`)[0];\n",
              "                popup_1914bce5423d2b04c09b9c4c535537f5.setContent(html_98d2313affb312b309ea2d27b025ab3f);\n",
              "            \n",
              "        \n",
              "\n",
              "        marker_975b24a1fbb6d562f58f172286a06f5d.bindPopup(popup_1914bce5423d2b04c09b9c4c535537f5)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "    \n",
              "            marker_975b24a1fbb6d562f58f172286a06f5d.bindTooltip(\n",
              "                `&lt;div&gt;\n",
              "                     Turku City Center Point\n",
              "                 &lt;/div&gt;`,\n",
              "                {\n",
              "  &quot;sticky&quot;: true,\n",
              "}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                marker_975b24a1fbb6d562f58f172286a06f5d.setIcon(icon_465ccf10f651758d871749fe023615de);\n",
              "            \n",
              "    \n",
              "            var rectangle_27ace1c210a27bfb7b9ee5a0f6f9831a = L.rectangle(\n",
              "                [[60.45, 22.25], [60.55, 22.35]],\n",
              "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.1, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
              "            ).addTo(map_4565ae6e5223343852e352e7140137cd);\n",
              "        \n",
              "    \n",
              "        var popup_e5336ce0117a6c92587a81e9d03f9d94 = L.popup({\n",
              "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
              "});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_c4fc06ce1a530a955957de39ca430be7 = $(`&lt;div id=&quot;html_c4fc06ce1a530a955957de39ca430be7&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Approximate 9km Grid Cell Area&lt;/div&gt;`)[0];\n",
              "                popup_e5336ce0117a6c92587a81e9d03f9d94.setContent(html_c4fc06ce1a530a955957de39ca430be7);\n",
              "            \n",
              "        \n",
              "\n",
              "        rectangle_27ace1c210a27bfb7b9ee5a0f6f9831a.bindPopup(popup_e5336ce0117a6c92587a81e9d03f9d94)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "    \n",
              "            var circle_marker_15a7b0bbf988cdfd559875bb276b7940 = L.circleMarker(\n",
              "                [60.4515, 22.2672],\n",
              "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;green&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;green&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 5, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
              "            ).addTo(map_4565ae6e5223343852e352e7140137cd);\n",
              "        \n",
              "    \n",
              "        var popup_04b66cca5de541687f77939912710367 = L.popup({\n",
              "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
              "});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_b0460766382f84fb5d92ea1b5a33ce34 = $(`&lt;div id=&quot;html_b0460766382f84fb5d92ea1b5a33ce34&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Market Square (City Center)&lt;/div&gt;`)[0];\n",
              "                popup_04b66cca5de541687f77939912710367.setContent(html_b0460766382f84fb5d92ea1b5a33ce34);\n",
              "            \n",
              "        \n",
              "\n",
              "        circle_marker_15a7b0bbf988cdfd559875bb276b7940.bindPopup(popup_04b66cca5de541687f77939912710367)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"cdsapi>=0.7.7\""
      ],
      "metadata": {
        "id": "ejepqwjFn8Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27c20b3-08c5-4c1a-9729-7aca106e14cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cdsapi>=0.7.7\n",
            "  Downloading cdsapi-0.7.7-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting ecmwf-datastores-client>=0.4.0 (from cdsapi>=0.7.7)\n",
            "  Downloading ecmwf_datastores_client-0.4.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (4.67.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (25.4.0)\n",
            "Collecting multiurl>=0.3.7 (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7)\n",
            "  Downloading multiurl-0.3.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (2026.1.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (1.17.0)\n",
            "Downloading cdsapi-0.7.7-py2.py3-none-any.whl (12 kB)\n",
            "Downloading ecmwf_datastores_client-0.4.2-py3-none-any.whl (29 kB)\n",
            "Downloading multiurl-0.3.7-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: multiurl, ecmwf-datastores-client, cdsapi\n",
            "Successfully installed cdsapi-0.7.7 ecmwf-datastores-client-0.4.2 multiurl-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcdf4"
      ],
      "metadata": {
        "id": "RvPUR0yStJcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b844a20-0ae2-4d99-e85b-813a978580a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netcdf4\n",
            "  Downloading netcdf4-1.7.4-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting cftime (from netcdf4)\n",
            "  Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2.0.2)\n",
            "Downloading netcdf4-1.7.4-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netcdf4\n",
            "Successfully installed cftime-1.6.5 netcdf4-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Updated configuration: removed the UID prefix as per the error instructions\n",
        "content = \"\"\"url: https://cds.climate.copernicus.eu/api\n",
        "key: c025f203-5930-4d9c-acd6-699c46be7fd8\"\"\"\n",
        "\n",
        "with open(os.path.expanduser('~/.cdsapirc'), 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Configuration updated! Now attempting to update the library...\")\n",
        "\n",
        "# Also update your library to the latest version to match the new API\n",
        "!pip install --upgrade cdsapi"
      ],
      "metadata": {
        "id": "xsU63P_1qIQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d87aac-b430-4e7c-8d27-7e15883ea62d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration updated! Now attempting to update the library...\n",
            "Requirement already satisfied: cdsapi in /usr/local/lib/python3.12/dist-packages (0.7.7)\n",
            "Requirement already satisfied: ecmwf-datastores-client>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (0.4.2)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi) (4.67.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (25.4.0)\n",
            "Requirement already satisfied: multiurl>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2026.1.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi\n",
        "import os\n",
        "import calendar\n",
        "\n",
        "# CRITICAL FIX: Set progress=False to prevent widget metadata creation\n",
        "c = cdsapi.Client(progress=False)\n",
        "\n",
        "# Range: Full year 2024 + January 2025\n",
        "tasks = [('2024', str(m).zfill(2)) for m in range(1, 13)] + [('2025', '01')]\n",
        "\n",
        "print(\"--- Data Download Started (GitHub-Safe Mode) ---\")\n",
        "\n",
        "for i, (year, month) in enumerate(tasks):\n",
        "    filename = f'turku_{year}_{month}.nc'\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"[{i+1}/13] {filename} already exists. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Determine days: Full month for 2024, but only Jan 1st for 2025\n",
        "    if year == '2025':\n",
        "        days = ['01']\n",
        "    else:\n",
        "        last_day = calendar.monthrange(int(year), int(month))[1]\n",
        "        days = [str(d).zfill(2) for d in range(1, last_day + 1)]\n",
        "\n",
        "    print(f\"[{i+1}/13] Requesting {month}/{year}...\")\n",
        "\n",
        "    try:\n",
        "        c.retrieve(\n",
        "            'reanalysis-era5-land',\n",
        "            {\n",
        "                'variable': [\n",
        "                    '2m_temperature',\n",
        "                    '10m_u_component_of_wind',\n",
        "                    '10m_v_component_of_wind',\n",
        "                    'surface_solar_radiation_downwards',\n",
        "                ],\n",
        "                'year': year,\n",
        "                'month': month,\n",
        "                'day': days,\n",
        "                'time': [f\"{str(h).zfill(2)}:00\" for h in range(24)],\n",
        "                'area': [60.5, 22.3, 60.5, 22.3],\n",
        "                'format': 'netcdf',\n",
        "            },\n",
        "            filename)\n",
        "        # We print a success message that will stay in your GitHub logs\n",
        "        print(f\"      ✅ {filename} successfully downloaded and saved.\")\n",
        "    except Exception as e:\n",
        "        print(f\"      ❌ Failed {year}-{month}: {e}\")\n",
        "\n",
        "print(\"--- All Downloads Complete ---\")"
      ],
      "metadata": {
        "id": "FMNRWkaGoHXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c8a20f-d791-4a32-ed07-2dc116e9db7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:14:41,632 INFO [2026-02-25T00:00:00Z] Please note that the announced software upgrade for extracting geographical-area data from selected ERA5 and Seasonal Forecast datasets was successfully implemented on 25 February. For further details, please [visit our forum announcement](https://forum.ecmwf.int/t/software-upgrade-for-data-extraction-of-a-geographical-area-from-selected-era5-and-seasonal-forecast-datasets/14583).\n",
            "INFO:ecmwf.datastores.legacy_client:[2026-02-25T00:00:00Z] Please note that the announced software upgrade for extracting geographical-area data from selected ERA5 and Seasonal Forecast datasets was successfully implemented on 25 February. For further details, please [visit our forum announcement](https://forum.ecmwf.int/t/software-upgrade-for-data-extraction-of-a-geographical-area-from-selected-era5-and-seasonal-forecast-datasets/14583).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Download Started (GitHub-Safe Mode) ---\n",
            "[1/13] Requesting 01/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:14:41,909 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:14:41,912 INFO Request ID is cb01229d-a498-4e4a-a21a-3e7303a07e1b\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is cb01229d-a498-4e4a-a21a-3e7303a07e1b\n",
            "2026-03-01 08:14:42,046 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:14:55,886 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 08:15:15,131 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:23:03,044 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_01.nc successfully downloaded and saved.\n",
            "[2/13] Requesting 02/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:23:04,815 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:23:04,818 INFO Request ID is 64f14a58-2ee4-48e3-bbe9-92d44a9e37a3\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 64f14a58-2ee4-48e3-bbe9-92d44a9e37a3\n",
            "2026-03-01 08:23:04,948 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:23:18,745 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 08:29:25,316 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_02.nc successfully downloaded and saved.\n",
            "[3/13] Requesting 03/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:29:27,005 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:29:27,008 INFO Request ID is e5e6d4be-6446-4716-b9a3-898b69c824e1\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is e5e6d4be-6446-4716-b9a3-898b69c824e1\n",
            "2026-03-01 08:29:27,137 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:29:40,974 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 08:37:48,084 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_03.nc successfully downloaded and saved.\n",
            "[4/13] Requesting 04/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:37:49,746 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:37:49,748 INFO Request ID is 409f07bb-ecc6-4119-a1c5-1e543bdb139e\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 409f07bb-ecc6-4119-a1c5-1e543bdb139e\n",
            "2026-03-01 08:37:49,878 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:42:10,237 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_04.nc successfully downloaded and saved.\n",
            "[5/13] Requesting 05/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:42:12,078 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:42:12,080 INFO Request ID is 8d185a22-5285-4751-b117-a4c070852abf\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 8d185a22-5285-4751-b117-a4c070852abf\n",
            "2026-03-01 08:42:12,211 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:42:20,855 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 08:48:32,445 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_05.nc successfully downloaded and saved.\n",
            "[6/13] Requesting 06/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:48:37,465 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:48:37,467 INFO Request ID is e77c2057-3765-4140-ba8a-1b5d62650ff3\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is e77c2057-3765-4140-ba8a-1b5d62650ff3\n",
            "2026-03-01 08:48:37,589 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:48:51,556 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 08:54:58,092 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_06.nc successfully downloaded and saved.\n",
            "[7/13] Requesting 07/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 08:54:59,801 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 08:54:59,803 INFO Request ID is 892dffda-569e-4031-a894-a0750b8f9bed\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 892dffda-569e-4031-a894-a0750b8f9bed\n",
            "2026-03-01 08:54:59,940 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 08:55:33,280 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 09:03:21,301 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_07.nc successfully downloaded and saved.\n",
            "[8/13] Requesting 08/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 09:03:22,923 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 09:03:22,925 INFO Request ID is cc69b9f4-7598-4892-92e3-99e9735a327e\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is cc69b9f4-7598-4892-92e3-99e9735a327e\n",
            "2026-03-01 09:03:23,064 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 09:09:43,622 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_08.nc successfully downloaded and saved.\n",
            "[9/13] Requesting 09/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 09:09:45,240 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 09:09:45,242 INFO Request ID is 7fa798ec-5f11-4b74-944a-a49ee3d08026\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 7fa798ec-5f11-4b74-944a-a49ee3d08026\n",
            "2026-03-01 09:09:45,377 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 09:16:07,242 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_09.nc successfully downloaded and saved.\n",
            "[10/13] Requesting 10/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 09:16:08,958 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 09:16:08,961 INFO Request ID is 13293688-afea-4b2c-9b82-b4617ca2db69\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 13293688-afea-4b2c-9b82-b4617ca2db69\n",
            "2026-03-01 09:16:09,100 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 09:22:29,984 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_10.nc successfully downloaded and saved.\n",
            "[11/13] Requesting 11/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 09:22:31,612 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 09:22:31,615 INFO Request ID is 2543dbdf-462a-4775-9da7-4edc918bb6dd\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 2543dbdf-462a-4775-9da7-4edc918bb6dd\n",
            "2026-03-01 09:22:31,728 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 09:28:54,650 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_11.nc successfully downloaded and saved.\n",
            "[12/13] Requesting 12/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 09:28:56,526 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 09:28:56,529 INFO Request ID is 0eae8834-2900-42ad-9858-90cde1e423c6\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 0eae8834-2900-42ad-9858-90cde1e423c6\n",
            "2026-03-01 09:28:56,646 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 09:35:17,005 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_12.nc successfully downloaded and saved.\n",
            "[13/13] Requesting 01/2025...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-03-01 09:35:18,629 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2026-03-01 09:35:18,632 INFO Request ID is b644dbcd-4214-4051-aea5-5ece2c0ba7c3\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is b644dbcd-4214-4051-aea5-5ece2c0ba7c3\n",
            "2026-03-01 09:35:18,761 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2026-03-01 09:35:32,605 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2026-03-01 09:35:51,901 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2025_01.nc successfully downloaded and saved.\n",
            "--- All Downloads Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcdf4 h5netcdf"
      ],
      "metadata": {
        "id": "BEbXSK_zQsp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014739d4-3ac3-494f-848c-ef549df1fd54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.12/dist-packages (1.7.4)\n",
            "Requirement already satisfied: h5netcdf in /usr/local/lib/python3.12/dist-packages (1.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netcdf4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from h5netcdf) (26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 1. Setup paths\n",
        "file_list = sorted(glob.glob('turku_*.nc'))\n",
        "extract_dir = 'extracted_temp'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "all_data = []\n",
        "\n",
        "print(f\"--- Processing {len(file_list)} files ---\")\n",
        "\n",
        "for f in file_list:\n",
        "    try:\n",
        "        # ZIP check logic\n",
        "        with open(f, 'rb') as test_f:\n",
        "            is_zip = test_f.read(2) == b'PK'\n",
        "\n",
        "        if is_zip:\n",
        "            with zipfile.ZipFile(f, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "            inner_files = glob.glob(os.path.join(extract_dir, \"*.nc\"))\n",
        "            if inner_files:\n",
        "                ds = xr.open_dataset(inner_files[0], engine='netcdf4')\n",
        "                for extra in inner_files: os.remove(extra)\n",
        "        else:\n",
        "            ds = xr.open_dataset(f, engine='netcdf4')\n",
        "\n",
        "        # --- FIX: Rename 'time' dimension to 'valid_time' for compatibility if it exists ---\n",
        "        if 'time' in ds.dims:\n",
        "            ds = ds.rename({'time': 'valid_time'})\n",
        "\n",
        "        # --- CRITICAL FIX: GHI DE-ACCUMULATION ---\n",
        "        # ERA5-Land ssrd is accumulated from 00:00 UTC.\n",
        "        # We subtract the previous hour from the current hour to get Joules per that specific hour.\n",
        "        ssrd_diff = ds['ssrd'].diff(dim='valid_time', label='upper')\n",
        "        first_hour = ds['ssrd'].isel(valid_time=0)\n",
        "\n",
        "        # Recombine: First hour + the differenced hours\n",
        "        ghi_joules = xr.concat([first_hour, ssrd_diff], dim='valid_time')\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = ds.to_dataframe().reset_index()\n",
        "\n",
        "        # Apply conversions\n",
        "        df['GHI_Wm2'] = ghi_joules.values.flatten() / 3600\n",
        "        df['Temperature_C'] = df['t2m'] - 273.15\n",
        "        df['Wind_Speed_ms'] = np.sqrt(df['u10']**2 + df['v10']**2)\n",
        "\n",
        "        all_data.append(df)\n",
        "        ds.close()\n",
        "\n",
        "        print(f\"✅ Processed: {f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error on {f}: {e}\")\n",
        "\n",
        "if all_data:\n",
        "    df_combined = pd.concat(all_data).sort_values('valid_time')\n",
        "\n",
        "    # 2. Format Time Columns\n",
        "    df_combined['valid_time'] = pd.to_datetime(df_combined['valid_time'])\n",
        "    df_combined['Date'] = df_combined['valid_time'].dt.strftime('%Y-%m-%d')\n",
        "    df_combined['Hour'] = df_combined['valid_time'].dt.strftime('%H:00')\n",
        "\n",
        "    # 3. Final selection and reorder\n",
        "    final_cols = ['Date', 'Hour', 'Temperature_C', 'Wind_Speed_ms', 'GHI_Wm2']\n",
        "    final_output = df_combined[final_cols]\n",
        "\n",
        "    # 4. Export\n",
        "    csv_name = 'Turku_Weather_Hourly_2024_Clean.csv'\n",
        "    final_output.to_csv(csv_name, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"SUCCESS: Saved to {csv_name}\")\n",
        "    print(f\"Total Rows: {len(final_output)}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Display preview\n",
        "    print(\"\\nData Preview (check if GHI_Wm2 looks realistic, e.g., 0 at night):\")\n",
        "    print(final_output.head(25)) # Showing 25 rows to see a full day cycle\n",
        "else:\n",
        "    print(\"No data frames found.\")"
      ],
      "metadata": {
        "id": "eyrOqHk1sSjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f626abf-71c4-43c4-9f45-d1cf4995d6c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing 13 files ---\n",
            "✅ Processed: turku_2024_01.nc\n",
            "✅ Processed: turku_2024_02.nc\n",
            "✅ Processed: turku_2024_03.nc\n",
            "✅ Processed: turku_2024_04.nc\n",
            "✅ Processed: turku_2024_05.nc\n",
            "✅ Processed: turku_2024_06.nc\n",
            "✅ Processed: turku_2024_07.nc\n",
            "✅ Processed: turku_2024_08.nc\n",
            "✅ Processed: turku_2024_09.nc\n",
            "✅ Processed: turku_2024_10.nc\n",
            "✅ Processed: turku_2024_11.nc\n",
            "✅ Processed: turku_2024_12.nc\n",
            "✅ Processed: turku_2025_01.nc\n",
            "\n",
            "========================================\n",
            "SUCCESS: Saved to Turku_Weather_Hourly_2024_Clean.csv\n",
            "Total Rows: 8808\n",
            "========================================\n",
            "\n",
            "Data Preview (check if GHI_Wm2 looks realistic, e.g., 0 at night):\n",
            "          Date   Hour  Temperature_C  Wind_Speed_ms     GHI_Wm2\n",
            "0   2024-01-01  00:00     -14.486420       2.236743  169.474442\n",
            "1   2024-01-01  01:00     -14.128998       2.165980 -169.474442\n",
            "2   2024-01-01  02:00     -13.787689       2.090343    0.000000\n",
            "3   2024-01-01  03:00     -13.063324       2.009852    0.000000\n",
            "4   2024-01-01  04:00     -12.227142       2.373250    0.000000\n",
            "5   2024-01-01  05:00     -11.744965       2.263318    0.000000\n",
            "6   2024-01-01  06:00     -11.416595       2.430776    0.000000\n",
            "7   2024-01-01  07:00     -12.747650       2.607541    0.000000\n",
            "8   2024-01-01  08:00     -12.938080       2.611824    0.432778\n",
            "9   2024-01-01  09:00     -13.129974       3.036740   19.727777\n",
            "10  2024-01-01  10:00     -13.517181       3.260260   42.092224\n",
            "11  2024-01-01  11:00     -14.022308       3.349888   43.130001\n",
            "12  2024-01-01  12:00     -14.412689       3.363450   45.997223\n",
            "13  2024-01-01  13:00     -14.814545       3.163138   23.062778\n",
            "14  2024-01-01  14:00     -15.160248       3.024627    1.480556\n",
            "15  2024-01-01  15:00     -15.497650       2.945954    0.000000\n",
            "16  2024-01-01  16:00     -15.871185       2.916194    0.000000\n",
            "17  2024-01-01  17:00     -16.358490       2.938740    0.000000\n",
            "18  2024-01-01  18:00     -16.861908       3.054510    0.000000\n",
            "19  2024-01-01  19:00     -17.130463       3.065264    0.000000\n",
            "20  2024-01-01  20:00     -17.388367       3.016225    0.000000\n",
            "21  2024-01-01  21:00     -17.533783       2.740594    0.000000\n",
            "22  2024-01-01  22:00     -17.614838       2.797941    0.000000\n",
            "23  2024-01-01  23:00     -17.561722       2.859434    0.000000\n",
            "24  2024-01-02  00:00     -17.653000       2.827637    0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 1. Setup paths\n",
        "file_list = sorted(glob.glob('turku_*.nc'))\n",
        "extract_dir = 'extracted_temp'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "all_data = []\n",
        "\n",
        "print(f\"--- Processing {len(file_list)} files ---\")\n",
        "\n",
        "for f in file_list:\n",
        "    try:\n",
        "        # ZIP check logic\n",
        "        with open(f, 'rb') as test_f:\n",
        "            is_zip = test_f.read(2) == b'PK'\n",
        "\n",
        "        if is_zip:\n",
        "            with zipfile.ZipFile(f, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "            inner_files = glob.glob(os.path.join(extract_dir, \"*.nc\"))\n",
        "            if inner_files:\n",
        "                ds = xr.open_dataset(inner_files[0], engine='netcdf4')\n",
        "                for extra in inner_files: os.remove(extra)\n",
        "        else:\n",
        "            ds = xr.open_dataset(f, engine='netcdf4')\n",
        "\n",
        "        # --- DYNAMIC DIMENSION DETECTION ---\n",
        "        # Detect if the time dimension is 'time' or 'valid_time'\n",
        "        t_dim = 'valid_time' if 'valid_time' in ds.dims else 'time'\n",
        "\n",
        "        # --- GHI DE-ACCUMULATION ---\n",
        "        # Using the detected dimension name\n",
        "        ssrd_diff = ds['ssrd'].diff(dim=t_dim, label='upper')\n",
        "        first_hour = ds['ssrd'].isel({t_dim: 0})\n",
        "\n",
        "        # Recombine: First hour + the differenced hours\n",
        "        ghi_joules = xr.concat([first_hour, ssrd_diff], dim=t_dim)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = ds.to_dataframe().reset_index()\n",
        "\n",
        "        # Apply conversions (Flatten to ensure 1D array matches DF length)\n",
        "        df['GHI_Wm2'] = ghi_joules.values.flatten() / 3600\n",
        "        #FIX: Clip negative values to zero\n",
        "        df['GHI_Wm2'] = df['GHI_Wm2'].clip(lower=0)\n",
        "\n",
        "        df['Temperature_C'] = df['t2m'] - 273.15\n",
        "        df['Wind_Speed_ms'] = np.sqrt(df['u10']**2 + df['v10']**2)\n",
        "\n",
        "        all_data.append(df)\n",
        "        ds.close()\n",
        "\n",
        "        print(f\"✅ Processed: {f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error on {f}: {e}\")\n",
        "\n",
        "if all_data:\n",
        "    df_combined = pd.concat(all_data)\n",
        "\n",
        "    # Standardize time column name for the final CSV\n",
        "    time_col = 'valid_time' if 'valid_time' in df_combined.columns else 'time'\n",
        "    df_combined = df_combined.sort_values(time_col)\n",
        "\n",
        "    # 2. Format Time Columns\n",
        "    df_combined[time_col] = pd.to_datetime(df_combined[time_col])\n",
        "    df_combined['Date'] = df_combined[time_col].dt.strftime('%Y-%m-%d')\n",
        "    df_combined['Hour'] = df_combined[time_col].dt.strftime('%H:00')\n",
        "\n",
        "    # 3. Final selection and reorder\n",
        "    final_cols = ['Date', 'Hour', 'Temperature_C', 'Wind_Speed_ms', 'GHI_Wm2']\n",
        "    final_output = df_combined[final_cols]\n",
        "\n",
        "    # 4. Export\n",
        "    csv_name = 'Turku_Weather_Hourly_Final.csv'\n",
        "    final_output.to_csv(csv_name, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"SUCCESS: Saved to {csv_name}\")\n",
        "    print(f\"Total Rows: {len(final_output)}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Display preview\n",
        "    print(\"\\nData Preview:\")\n",
        "    print(final_output.head(10))\n",
        "else:\n",
        "    print(\"No data frames found. Check if the files are corrupted or empty.\")"
      ],
      "metadata": {
        "id": "QSGkSquryFmP",
        "outputId": "124a3def-52f9-4f5b-f9ba-3565c1966684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing 13 files ---\n",
            "✅ Processed: turku_2024_01.nc\n",
            "✅ Processed: turku_2024_02.nc\n",
            "✅ Processed: turku_2024_03.nc\n",
            "✅ Processed: turku_2024_04.nc\n",
            "✅ Processed: turku_2024_05.nc\n",
            "✅ Processed: turku_2024_06.nc\n",
            "✅ Processed: turku_2024_07.nc\n",
            "✅ Processed: turku_2024_08.nc\n",
            "✅ Processed: turku_2024_09.nc\n",
            "✅ Processed: turku_2024_10.nc\n",
            "✅ Processed: turku_2024_11.nc\n",
            "✅ Processed: turku_2024_12.nc\n",
            "✅ Processed: turku_2025_01.nc\n",
            "\n",
            "========================================\n",
            "SUCCESS: Saved to Turku_Weather_Hourly_Final.csv\n",
            "Total Rows: 8808\n",
            "========================================\n",
            "\n",
            "Data Preview:\n",
            "         Date   Hour  Temperature_C  Wind_Speed_ms     GHI_Wm2\n",
            "0  2024-01-01  00:00     -14.486420       2.236743  169.474442\n",
            "1  2024-01-01  01:00     -14.128998       2.165980    0.000000\n",
            "2  2024-01-01  02:00     -13.787689       2.090343    0.000000\n",
            "3  2024-01-01  03:00     -13.063324       2.009852    0.000000\n",
            "4  2024-01-01  04:00     -12.227142       2.373250    0.000000\n",
            "5  2024-01-01  05:00     -11.744965       2.263318    0.000000\n",
            "6  2024-01-01  06:00     -11.416595       2.430776    0.000000\n",
            "7  2024-01-01  07:00     -12.747650       2.607541    0.000000\n",
            "8  2024-01-01  08:00     -12.938080       2.611824    0.432778\n",
            "9  2024-01-01  09:00     -13.129974       3.036740   19.727777\n"
          ]
        }
      ]
    }
  ]
}