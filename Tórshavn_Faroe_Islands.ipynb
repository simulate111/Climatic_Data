{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8W/hnVyTaDz9c+JeOvfgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/T%C3%B3rshavn_Faroe_Islands.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxlyr4KCnLd0",
        "outputId": "c4c10954-31ff-4306-de79-dea5bb11050c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Data Retrieval for Faroe Islands (2024) ---\n",
            "Using new DMI Open Data Endpoint (No Authentication Required)\n",
            "\n",
            "Checking Station 06011...\n",
            " > SUCCESS: Station 06011 is active and has data.\n",
            "\n",
            "Fetching full 2024 datasets from Active Station: 06011...\n",
            " > Requesting Temperature_C...\n",
            "   > Got 4866 hourly records for Temperature_C.\n",
            " > Requesting Wind_Speed_ms...\n",
            "   > Got 4866 hourly records for Wind_Speed_ms.\n",
            "\n",
            "Merging and formatting...\n",
            "------------------------------\n",
            "         Date   Hour  Temperature_C  Wind_Speed_ms\n",
            "0  2024-06-12  07:00       9.500000       3.100000\n",
            "1  2024-06-12  08:00       9.916667       3.916667\n",
            "2  2024-06-12  09:00      10.233333       4.766667\n",
            "3  2024-06-12  10:00      11.166667       4.750000\n",
            "4  2024-06-12  11:00      11.983333       3.050000\n",
            "------------------------------\n",
            "Success! Data saved to: Faroe_Station_06011_Wind_Temp_2024.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# NEW ENDPOINT (No API Key required)\n",
        "base_url = \"https://opendataapi.dmi.dk/v2/metObs/collections/observation/items\"\n",
        "\n",
        "start_date = \"2024-01-01T00:00:00Z\"\n",
        "end_date = \"2025-01-01T00:00:00Z\"\n",
        "limit = 300000\n",
        "\n",
        "# PRIORITY LIST OF STATIONS\n",
        "# 1. Tórshavn (06011) - Primary, but often managed by local FMO (might be empty here)\n",
        "# 2. Vágar Airport (06010) - Reliable fallback\n",
        "# 3. Akraberg (06009) - Southern lighthouse\n",
        "station_candidates = [\"06011\", \"06010\", \"06009\"]\n",
        "\n",
        "# Parameters to fetch\n",
        "tasks = [\n",
        "    {\"param\": \"temp_dry\",   \"name\": \"Temperature_C\"},\n",
        "    {\"param\": \"wind_speed\", \"name\": \"Wind_Speed_ms\"}\n",
        "]\n",
        "\n",
        "active_station = None\n",
        "dfs = []\n",
        "\n",
        "print(\"--- Starting Data Retrieval for Faroe Islands (2024) ---\")\n",
        "print(\"Using new DMI Open Data Endpoint (No Authentication Required)\")\n",
        "\n",
        "# Step 1: Find a working station\n",
        "for station_id in station_candidates:\n",
        "    print(f\"\\nChecking Station {station_id}...\")\n",
        "\n",
        "    # Test fetch to see if data exists\n",
        "    test_params = {\n",
        "        \"stationId\": station_id,\n",
        "        \"datetime\": f\"{start_date}/{end_date}\",\n",
        "        \"parameterId\": \"temp_dry\",\n",
        "        \"limit\": 10\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(base_url, params=test_params)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            data = r.json().get('features', [])\n",
        "            if len(data) > 0:\n",
        "                print(f\" > SUCCESS: Station {station_id} is active and has data.\")\n",
        "                active_station = station_id\n",
        "                break\n",
        "            else:\n",
        "                print(f\" > Station {station_id} returned 0 rows. Trying next...\")\n",
        "        else:\n",
        "            print(f\" > Error checking station {station_id}: {r.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\" > Connection failed for {station_id}: {e}\")\n",
        "\n",
        "if not active_station:\n",
        "    print(\"\\nCRITICAL ERROR: No active stations found with data for 2024.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Fetch full data for the active station\n",
        "print(f\"\\nFetching full 2024 datasets from Active Station: {active_station}...\")\n",
        "\n",
        "for task in tasks:\n",
        "    print(f\" > Requesting {task['name']}...\")\n",
        "\n",
        "    params = {\n",
        "        \"stationId\": active_station,\n",
        "        \"datetime\": f\"{start_date}/{end_date}\",\n",
        "        \"parameterId\": task['param'],\n",
        "        \"limit\": limit\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(base_url, params=params)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            data = r.json().get('features', [])\n",
        "            records = []\n",
        "\n",
        "            for item in data:\n",
        "                records.append({\n",
        "                    'Time': item['properties']['observed'],\n",
        "                    task['name']: item['properties']['value']\n",
        "                })\n",
        "\n",
        "            df_temp = pd.DataFrame(records)\n",
        "\n",
        "            if not df_temp.empty:\n",
        "                df_temp['Time'] = pd.to_datetime(df_temp['Time'])\n",
        "\n",
        "                # Resample to Hourly Averages\n",
        "                df_temp = df_temp.set_index('Time').resample('h').mean()\n",
        "\n",
        "                dfs.append(df_temp)\n",
        "                print(f\"   > Got {len(df_temp)} hourly records for {task['name']}.\")\n",
        "            else:\n",
        "                print(f\"   > WARNING: No data found for {task['name']}.\")\n",
        "        else:\n",
        "            print(f\"   > API Error: {r.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   > Error: {e}\")\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "# Step 3: Merge and Save\n",
        "if dfs:\n",
        "    print(\"\\nMerging and formatting...\")\n",
        "    df_final = pd.concat(dfs, axis=1)\n",
        "    df_final = df_final.sort_index()\n",
        "\n",
        "    # Fill small gaps\n",
        "    df_final = df_final.interpolate(method='linear', limit=2)\n",
        "    df_final = df_final.dropna(how='all')\n",
        "\n",
        "    # Format columns\n",
        "    df_final = df_final.reset_index()\n",
        "    df_final['Date'] = df_final['Time'].dt.strftime('%Y-%m-%d')\n",
        "    df_final['Hour'] = df_final['Time'].dt.strftime('%H:%M')\n",
        "\n",
        "    cols = ['Date', 'Hour', 'Temperature_C', 'Wind_Speed_ms']\n",
        "    df_final = df_final[[c for c in cols if c in df_final.columns]]\n",
        "\n",
        "    filename = f\"Faroe_Station_{active_station}_Wind_Temp_2024.csv\"\n",
        "    df_final.to_csv(filename, index=False)\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(df_final.head())\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Success! Data saved to: {filename}\")\n",
        "else:\n",
        "    print(\"Failed to compile dataset.\")"
      ]
    }
  ]
}