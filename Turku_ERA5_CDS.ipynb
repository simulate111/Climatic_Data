{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmfhlhYTuj6AVilF8rQHtV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/General/blob/main/Turku_ERA5_CDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "\n",
        "# The precise City Center coordinates we chose\n",
        "lat, lon = 60.5, 22.3\n",
        "\n",
        "# 1. Initialize the map centered on Turku\n",
        "# We use 'cartodbpositron' for a clean, professional look that highlights markers\n",
        "m = folium.Map(location=[lat, lon], zoom_start=12, control_scale=True)\n",
        "\n",
        "# 2. Add a marker for the exact Grid Center\n",
        "folium.Marker(\n",
        "    [lat, lon],\n",
        "    popup=\"<b>ERA5-Land Grid Center</b><br>Lat: 60.5, Lon: 22.3\",\n",
        "    tooltip=\"Turku City Center Point\",\n",
        "    icon=folium.Icon(color='darkred', icon='info-sign')\n",
        ").add_to(m)\n",
        "\n",
        "# 3. Add a rectangle to show the ERA5-Land Grid Cell (approx 0.1 x 0.1 degrees)\n",
        "# This represents the actual area the weather data is calculated for.\n",
        "folium.Rectangle(\n",
        "    bounds=[[60.45, 22.25], [60.55, 22.35]],\n",
        "    color=\"blue\",\n",
        "    fill=True,\n",
        "    fill_opacity=0.1,\n",
        "    popup=\"Approximate 9km Grid Cell Area\"\n",
        ").add_to(m)\n",
        "\n",
        "# 4. Add a reference marker for the Market Square (Kauppatori)\n",
        "# to see how close it is to our data point.\n",
        "folium.CircleMarker(\n",
        "    location=[60.4515, 22.2672],\n",
        "    radius=5,\n",
        "    color=\"green\",\n",
        "    fill=True,\n",
        "    popup=\"Market Square (City Center)\"\n",
        ").add_to(m)\n",
        "\n",
        "# Display the map in Colab\n",
        "m"
      ],
      "metadata": {
        "id": "d37iTantaZ1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"cdsapi>=0.7.7\""
      ],
      "metadata": {
        "id": "ejepqwjFn8Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c768079-8d6a-4e86-b8be-a25e1b2c148c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cdsapi>=0.7.7 in /usr/local/lib/python3.12/dist-packages (0.7.7)\n",
            "Requirement already satisfied: ecmwf-datastores-client>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi>=0.7.7) (4.67.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (25.4.0)\n",
            "Requirement already satisfied: multiurl>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi>=0.7.7) (2025.11.12)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi>=0.7.7) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcdf4"
      ],
      "metadata": {
        "id": "RvPUR0yStJcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710d2db0-112c-41db-d616-2a8c4bc8d972"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.12/dist-packages (1.7.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netcdf4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2025.11.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from netcdf4) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Updated configuration: removed the UID prefix as per the error instructions\n",
        "content = \"\"\"url: https://cds.climate.copernicus.eu/api\n",
        "key: c025f203-5930-4d9c-acd6-699c46be7fd8\"\"\"\n",
        "\n",
        "with open(os.path.expanduser('~/.cdsapirc'), 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Configuration updated! Now attempting to update the library...\")\n",
        "\n",
        "# Also update your library to the latest version to match the new API\n",
        "!pip install --upgrade cdsapi"
      ],
      "metadata": {
        "id": "xsU63P_1qIQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de21534-d905-44ba-e155-28376602b45d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration updated! Now attempting to update the library...\n",
            "Requirement already satisfied: cdsapi in /usr/local/lib/python3.12/dist-packages (0.7.7)\n",
            "Requirement already satisfied: ecmwf-datastores-client>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi) (4.67.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (25.4.0)\n",
            "Requirement already satisfied: multiurl>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2025.11.12)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client>=0.4.0->cdsapi) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi\n",
        "import os\n",
        "import calendar\n",
        "\n",
        "# CRITICAL FIX: Set progress=False to prevent widget metadata creation\n",
        "c = cdsapi.Client(progress=False)\n",
        "\n",
        "# Range: Full year 2024 + January 2025\n",
        "tasks = [('2024', str(m).zfill(2)) for m in range(1, 13)] + [('2025', '01')]\n",
        "\n",
        "print(\"--- Data Download Started (GitHub-Safe Mode) ---\")\n",
        "\n",
        "for i, (year, month) in enumerate(tasks):\n",
        "    filename = f'turku_{year}_{month}.nc'\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"[{i+1}/13] {filename} already exists. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Determine days: Full month for 2024, but only Jan 1st for 2025\n",
        "    if year == '2025':\n",
        "        days = ['01']\n",
        "    else:\n",
        "        last_day = calendar.monthrange(int(year), int(month))[1]\n",
        "        days = [str(d).zfill(2) for d in range(1, last_day + 1)]\n",
        "\n",
        "    print(f\"[{i+1}/13] Requesting {month}/{year}...\")\n",
        "\n",
        "    try:\n",
        "        c.retrieve(\n",
        "            'reanalysis-era5-land',\n",
        "            {\n",
        "                'variable': [\n",
        "                    '2m_temperature',\n",
        "                    '10m_u_component_of_wind',\n",
        "                    '10m_v_component_of_wind',\n",
        "                    'surface_solar_radiation_downwards',\n",
        "                ],\n",
        "                'year': year,\n",
        "                'month': month,\n",
        "                'day': days,\n",
        "                'time': [f\"{str(h).zfill(2)}:00\" for h in range(24)],\n",
        "                'area': [60.5, 22.3, 60.5, 22.3],\n",
        "                'format': 'netcdf',\n",
        "            },\n",
        "            filename)\n",
        "        # We print a success message that will stay in your GitHub logs\n",
        "        print(f\"      ✅ {filename} successfully downloaded and saved.\")\n",
        "    except Exception as e:\n",
        "        print(f\"      ❌ Failed {year}-{month}: {e}\")\n",
        "\n",
        "print(\"--- All Downloads Complete ---\")"
      ],
      "metadata": {
        "id": "FMNRWkaGoHXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739a28f5-f9b2-4cb7-bf8e-92e7b10bb8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-20 06:26:19,812 INFO [2025-12-03T00:00:00Z] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-03T00:00:00Z] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Download Started (GitHub-Safe Mode) ---\n",
            "[1/13] Requesting 01/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-20 06:26:20,637 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2025-12-20 06:26:20,640 INFO Request ID is 68e9d6c7-fcab-4cbb-a751-c4a10823146a\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 68e9d6c7-fcab-4cbb-a751-c4a10823146a\n",
            "2025-12-20 06:26:20,845 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2025-12-20 06:26:35,072 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2025-12-20 06:26:42,858 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2025-12-20 06:26:54,734 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2025-12-20 06:32:43,331 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ✅ turku_2024_01.nc successfully downloaded and saved.\n",
            "[2/13] Requesting 02/2024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-20 06:32:46,005 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "INFO:ecmwf.datastores.legacy_client:[2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview)\n",
            "2025-12-20 06:32:46,007 INFO Request ID is ccf5a7e8-16a2-4c17-8e26-49c05bc5c9a3\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is ccf5a7e8-16a2-4c17-8e26-49c05bc5c9a3\n",
            "2025-12-20 06:32:46,217 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2025-12-20 06:33:08,206 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcdf4 h5netcdf"
      ],
      "metadata": {
        "id": "BEbXSK_zQsp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 1. Setup paths\n",
        "file_list = sorted(glob.glob('turku_*.nc'))\n",
        "extract_dir = 'extracted_temp'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "all_data = []\n",
        "\n",
        "print(f\"--- Processing {len(file_list)} files ---\")\n",
        "\n",
        "for f in file_list:\n",
        "    try:\n",
        "        # ZIP check\n",
        "        with open(f, 'rb') as test_f:\n",
        "            is_zip = test_f.read(2) == b'PK'\n",
        "\n",
        "        if is_zip:\n",
        "            with zipfile.ZipFile(f, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "            inner_files = glob.glob(os.path.join(extract_dir, \"*.nc\"))\n",
        "            if inner_files:\n",
        "                ds = xr.open_dataset(inner_files[0], engine='netcdf4')\n",
        "                df = ds.to_dataframe().reset_index()\n",
        "                all_data.append(df)\n",
        "                for extra in inner_files: os.remove(extra)\n",
        "        else:\n",
        "            ds = xr.open_dataset(f, engine='netcdf4')\n",
        "            df = ds.to_dataframe().reset_index()\n",
        "            all_data.append(df)\n",
        "\n",
        "        print(f\"✅ Processed: {f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error on {f}: {e}\")\n",
        "\n",
        "if all_data:\n",
        "    df_combined = pd.concat(all_data).sort_values('valid_time')\n",
        "\n",
        "    # 2. Convert and Split Date and Hour\n",
        "    df_combined['valid_time'] = pd.to_datetime(df_combined['valid_time'])\n",
        "\n",
        "    # Extract Date as YYYY-MM-DD\n",
        "    df_combined['Date'] = df_combined['valid_time'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    # Extract Hour and format as HH:00 (e.g., 01:00)\n",
        "    df_combined['Hour'] = df_combined['valid_time'].dt.strftime('%H:00')\n",
        "\n",
        "    # 3. Unit Conversions\n",
        "    df_combined['Temperature_C'] = df_combined['t2m'] - 273.15\n",
        "    df_combined['Wind_Speed_ms'] = np.sqrt(df_combined['u10']**2 + df_combined['v10']**2)\n",
        "    df_combined['GHI_Wm2'] = df_combined['ssrd'] / 3600\n",
        "\n",
        "    # 4. Final selection and reorder\n",
        "    final_cols = ['Date', 'Hour', 'Temperature_C', 'Wind_Speed_ms', 'GHI_Wm2']\n",
        "    final_output = df_combined[final_cols]\n",
        "\n",
        "    # 5. Export\n",
        "    csv_name = 'Turku_Weather_Hourly_2024_Clean.csv'\n",
        "    final_output.to_csv(csv_name, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"SUCCESS: Saved to {csv_name}\")\n",
        "    print(f\"Total Rows: {len(final_output)}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Display preview for GitHub logs\n",
        "    print(\"\\nData Preview (showing top 5 rows):\")\n",
        "    print(final_output.head())\n",
        "else:\n",
        "    print(\"No data frames found. Make sure the .nc files were downloaded correctly.\")"
      ],
      "metadata": {
        "id": "eyrOqHk1sSjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}